{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdddbae",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to Ray Core by Example\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4d0ecd",
   "metadata": {},
   "source": [
    "Implement a function in Ray Core to understand how Ray works and its basic concepts.\n",
    "Python programmers from those with less experience to those who are interested in advanced tasks,\n",
    "can start working with distributed computing using Python by learning the Ray Core API.\n",
    "\n",
    "This notebook has been modified for pedagogical reasons from the original notebook in ray-project.\n",
    "\n",
    "## Install Ray\n",
    "\n",
    "Install Ray with the following command if you have not done so already.\n",
    "\n",
    "\n",
    "If you are running this inside the provided docker container with ray and jupyter already installed. Skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install ray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be9d3c98",
   "metadata": {},
   "source": [
    "## Ray Core\n",
    "\n",
    "Start a local cluster by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c05481-727b-449e-bb70-2dc91ad101b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.is_initialized() # check if ray is initialized in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea62bd0-e4f5-4c1a-9585-8e92275ac67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find any active Ray processes.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray stop --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b29378-6594-4fa5-9663-3a9ced3f0c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "\n",
      "\u001b[37mLocal node IP\u001b[39m: \u001b[1m172.17.0.2\u001b[22m\n",
      "\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\u001b[32mRay runtime started.\u001b[39m\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\n",
      "\u001b[36mNext steps\u001b[39m\n",
      "  To add another node to this Ray cluster, run\n",
      "  \u001b[1m  ray start --address='172.17.0.2:6379'\u001b[22m\n",
      "  \n",
      "  To connect to this Ray cluster:\n",
      "    \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "    ray\u001b[35m.\u001b[39m\u001b[26minit()\n",
      "  \n",
      "  To submit a Ray job using the Ray Jobs CLI:\n",
      "  \u001b[1m  RAY_ADDRESS='http://172.17.0.2:8265' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
      "  \n",
      "  See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
      "  for more information on submitting Ray jobs to the Ray cluster.\n",
      "  \n",
      "  To terminate the Ray runtime, run\n",
      "  \u001b[1m  ray stop\u001b[22m\n",
      "  \n",
      "  To view the status of the cluster, use\n",
      "    \u001b[1mray status\u001b[22m\u001b[26m\n",
      "  \n",
      "  To monitor and debug Ray, view the dashboard at \n",
      "    \u001b[1m172.17.0.2:8265\u001b[22m\u001b[26m\n",
      "  \n",
      "  \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray start --head --dashboard-host='0.0.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7c377-8d62-4768-87d2-588943a5885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f630bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 04:51:17,585\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m172.17.0.2:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c9a38b37a4492d8b274c025ab2da67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.9.22</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.47.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://172.17.0.2:8265\" target=\"_blank\">http://172.17.0.2:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='172.17.0.2:8265', python_version='3.9.22', ray_version='2.47.0', ray_commit='6f4c0c0b3e9ff4fc485111adbbc613ade819548b')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Raylet is terminated. Termination is unexpected. Possible reasons include: (1) SIGKILL by the user or system OOM killer, (2) Invalid memory access from Raylet causing SIGSEGV or SIGBUS, (3) Other termination signals. Last 20 lines of the Raylet logs:\n",
      "    [state-dump] \tNodeManager.deadline_timer.record_metrics - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.ScheduleAndDispatchTasks - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.deadline_timer.debug_state_dump - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 1.266 ms, total = 1.266 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.CheckForUnexpectedWorkerDisconnects - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] DebugString() time ms: 0\n",
      "    [state-dump] \n",
      "    [state-dump] \n",
      "    [2025-07-19 04:51:17,504 I 46880 46880] (raylet) accessor.cc:768: Received notification for node, IsAlive = 1 node_id=0f910f82d91f44c1bd892c444570a10356865d407c77eb7da86f61a8\n",
      "    [2025-07-19 04:51:17,597 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46936, the token is 0\n",
      "    [2025-07-19 04:51:17,599 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46937, the token is 1\n",
      "    [2025-07-19 04:51:17,602 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46938, the token is 2\n",
      "    [2025-07-19 04:51:17,604 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46939, the token is 3\n",
      "    [2025-07-19 04:51:17,607 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46940, the token is 4\n",
      "    [2025-07-19 04:51:17,609 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46941, the token is 5\n",
      "    [2025-07-19 04:51:17,612 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46942, the token is 6\n",
      "    [2025-07-19 04:51:17,615 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46943, the token is 7\n",
      "    [2025-07-19 04:51:18,566 I 46880 46903] (raylet) object_store.cc:38: Object store current usage 8e-09 / 9.6353 GB.\n",
      "    [2025-07-19 04:51:18,896 I 46880 46880] (raylet) worker_pool.cc:724: Job 01000000 already started in worker pool.\n",
      "\n",
      "\u001b[33m(raylet)\u001b[0m The node with node id: 0f910f82d91f44c1bd892c444570a10356865d407c77eb7da86f61a8 and address: 172.17.0.2 and node name: 172.17.0.2 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n",
      "\u001b[33m(raylet)\u001b[0m Raylet is terminated. Termination is unexpected. Possible reasons include: (1) SIGKILL by the user or system OOM killer, (2) Invalid memory access from Raylet causing SIGSEGV or SIGBUS, (3) Other termination signals. Last 20 lines of the Raylet logs:\n",
      "    [state-dump] \tNodeManager.deadline_timer.record_metrics - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.ScheduleAndDispatchTasks - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.deadline_timer.debug_state_dump - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 1.266 ms, total = 1.266 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] \tNodeManager.CheckForUnexpectedWorkerDisconnects - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s\n",
      "    [state-dump] DebugString() time ms: 0\n",
      "    [state-dump] \n",
      "    [state-dump] \n",
      "    [2025-07-19 04:51:17,504 I 46880 46880] (raylet) accessor.cc:768: Received notification for node, IsAlive = 1 node_id=0f910f82d91f44c1bd892c444570a10356865d407c77eb7da86f61a8\n",
      "    [2025-07-19 04:51:17,597 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46936, the token is 0\n",
      "    [2025-07-19 04:51:17,599 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46937, the token is 1\n",
      "    [2025-07-19 04:51:17,602 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46938, the token is 2\n",
      "    [2025-07-19 04:51:17,604 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46939, the token is 3\n",
      "    [2025-07-19 04:51:17,607 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46940, the token is 4\n",
      "    [2025-07-19 04:51:17,609 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46941, the token is 5\n",
      "    [2025-07-19 04:51:17,612 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46942, the token is 6\n",
      "    [2025-07-19 04:51:17,615 I 46880 46880] (raylet) worker_pool.cc:527: Started worker process with pid 46943, the token is 7\n",
      "    [2025-07-19 04:51:18,566 I 46880 46903] (raylet) object_store.cc:38: Object store current usage 8e-09 / 9.6353 GB.\n",
      "    [2025-07-19 04:51:18,896 I 46880 46880] (raylet) worker_pool.cc:724: Job 01000000 already started in worker pool.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(dashboard_host='0.0.0.0') # use this to connect to existing local ray cluster only\n",
    "#ray.init(address='auto',dashboard_host='0.0.0.0') # use this to connect to existing local ray cluster only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0defbbaf-9140-460c-95b3-daca895c8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2025-07-19 04:51:24.422253 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Active:\n",
      " 1 node_0f910f82d91f44c1bd892c444570a10356865d407c77eb7da86f61a8\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Total Usage:\n",
      " 0.0/8.0 CPU\n",
      " 0B/20.94GiB memory\n",
      " 0B/8.97GiB object_store_memory\n",
      "\n",
      "Total Constraints:\n",
      " (no request_resources() constraints)\n",
      "Total Demands:\n",
      " (no resource demands)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c12cf35-670b-4922-ac5d-dface12b4bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized() # check if ray is initialized in this notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6314973a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Note the following lines in the output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75826f4",
   "metadata": {},
   "source": [
    "```\n",
    "... INFO INFO worker.py:1908 -- Started a local Ray instance. View the dashboard at 172.17.0.2:8265 \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c837608",
   "metadata": {},
   "source": [
    "These messages indicate that the Ray cluster is working as expected. In this example output, the address of the Ray dashboard is `http://172.17.0.2:8265`. Access the Ray dashboard at the address on the first line of your output. The Ray dashboard displays information such as the number of CPU cores available and the total utilization of the current Ray application.\n",
    "This is a typical output for a laptop:\n",
    "\n",
    "```\n",
    "Resources\n",
    "---------------------------------------------------------------\n",
    "Total Usage:\n",
    " 0.0/8.0 CPU\n",
    " 0B/20.97GiB memory\n",
    " 0B/8.99GiB object_store_memory\n",
    "```\n",
    "\n",
    "You can also manage and debug the cluster with API or CLI commands as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525d7b9-426b-4e82-8877-5a7931b36166",
   "metadata": {},
   "source": [
    "## Cluster Debugging Basics\n",
    "\n",
    "We may want to stop a cluster and restart it or check its status. \n",
    "Here are some useful commands to debug a cluster:\n",
    "\n",
    "- [Ray Core API](https://docs.ray.io/en/latest/ray-core/api/core.html#core-api)\n",
    "  - [ray.init()](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html#ray.init): Connect to an existing Ray cluster or start one and connect to it.\n",
    "  - [ray.shutdown()](https://docs.ray.io/en/latest/ray-core/api/doc/ray.shutdown.html#ray.shutdown): Disconnect the worker, and terminate processes started by ray.init().\n",
    "  - [ray.is_initialized()](https://docs.ray.io/en/latest/ray-core/api/doc/ray.is_initialized.html#ray.is_initialized): Check if ray.init has been called yet.\n",
    "- [Ray Core CLI](https://docs.ray.io/en/latest/ray-core/api/cli.html#ray-core-cli)\n",
    "  - [ray status](https://docs.ray.io/en/latest/ray-core/api/cli.html#ray-status): Print cluster status, including autoscaling info.\n",
    "- [Ray Cluster Management CLI](https://docs.ray.io/en/latest/cluster/cli.html#cluster-management-cli)\n",
    "  - [ray start](https://docs.ray.io/en/latest/cluster/cli.html#ray-start): Start Ray processes manually on the local machine.\n",
    "  - [ray stop](https://docs.ray.io/en/latest/cluster/cli.html#ray-stop): Stop Ray processes manually on the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6e4f587-cd06-4723-a9b8-b7dd3a7ac59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to shutdown a ray cluster started with ray.init()\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e6adda2-59e9-4d0b-8a81-1b5aff1f3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2025-07-18 07:36:46.219267 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Active:\n",
      " 1 node_d2a34ab9f9b5e2e53393699b96c59fc172d7ddd218676ada97bd3ea0\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Total Usage:\n",
      " 0.0/8.0 CPU\n",
      " 0B/20.97GiB memory\n",
      " 0B/8.99GiB object_store_memory\n",
      "\n",
      "Total Constraints:\n",
      " (no request_resources() constraints)\n",
      "Total Demands:\n",
      " (no resource demands)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# precede CLI commands with ! in jupyter to run in shell\n",
    "! ray status "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf542ed9",
   "metadata": {},
   "source": [
    "Next, is a brief introduction to the Ray Core API, which we refer to as the Ray API.\n",
    "The Ray API builds on concepts such as decorators, functions, and classes, that are familiar to Python programmers.\n",
    "It is a universal programming interface for distributed computing. \n",
    "The engine handles the complicated work, allowing developers to use Ray with existing Python libraries and systems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d1a3bf",
   "metadata": {},
   "source": [
    "## Your First Ray API Example\n",
    "\n",
    "The following function retrieves and processes\n",
    "data from a database. The dummy `database` is a plain Python list containing the\n",
    "words of the title of the [\"Learning Ray\" book](https://www.amazon.com/Learning-Ray-Flexible-Distributed-Machine/dp/1098117220/).\n",
    "The `sleep` function pauses for a certain amount of time to simulate the cost of accessing and processing data from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e053331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "database = [\n",
    "    \"Learning\", \"Ray\",\n",
    "    \"Flexible\", \"Distributed\", \"Python\", \"for\", \"Machine\", \"Learning\"\n",
    "]\n",
    "\n",
    "\n",
    "def retrieve(item):\n",
    "    time.sleep(item / 10.)\n",
    "    return item, database[item]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b518f4f",
   "metadata": {},
   "source": [
    "If the item with index 5 takes half a second `(5 / 10.)`, an estimate of the total runtime to retrieve all eight items sequentially is `(0+1+2+3+4+5+6+7)/10. = 2.8` seconds.\n",
    "Run the following code to get the actual time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0091149",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.80 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "def print_runtime(input_data, start_time):\n",
    "    print(f'Runtime: {time.time() - start_time:.2f} seconds, data:')\n",
    "    print(*input_data, sep=\"\\n\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "data = [retrieve(item) for item in range(8)]\n",
    "print_runtime(data, start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97aa047d",
   "metadata": {},
   "source": [
    "The total time to run the function is 2.82 seconds in this example, but time may be different for your computer.\n",
    "Note that this basic Python version cannot run the function simultaneously."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30291db3",
   "metadata": {},
   "source": [
    "You may expect that Python list comprehensions are more efficient. The measured runtime of 2.8 seconds is actually the worst case scenario.\n",
    "Although this program \"sleeps\" for most of its runtime, it is slow because of the Global Interpreter Lock (GIL)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ebb32d4",
   "metadata": {},
   "source": [
    "### Ray Tasks\n",
    "\n",
    "This task can benefit from parallelization. If it is perfectly distributed, the runtime should not take much longer than the slowest subtask,\n",
    "that is, `7/10. = 0.7` seconds.\n",
    "To extend this example to run in parallel on Ray, start by using the @ray.remote decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e21e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def retrieve_task(item):\n",
    "    return retrieve(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935a4062",
   "metadata": {},
   "source": [
    "With the decorator, the function `retrieve_task` becomes a ray-remote-functions [Ray task](https://docs.ray.io/en/latest/ray-core/tasks.html#tasks).\n",
    "A Ray task is a function that Ray executes on a different process from where\n",
    "it was called, and possibly on a different machine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78afc80a",
   "metadata": {},
   "source": [
    "Ray is convenient to use because you can continue writing Python code,\n",
    "without having to significantly change your approach or programming style.\n",
    "Using the `@ray.remote` decorator on the retrieve function is the intended use of decorators,\n",
    "and you did not modify the original code in this example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5dc2e18",
   "metadata": {},
   "source": [
    "To retrieve database entries and measure performance, you do not need to make many changes to the code. Here's an overview of the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a34697da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.72 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "object_references = [\n",
    "    retrieve_task.remote(item) for item in range(8)\n",
    "]\n",
    "data = ray.get(object_references)\n",
    "print_runtime(data, start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df4087c",
   "metadata": {},
   "source": [
    "Running the task in parallel requires two minor code modifications.\n",
    "To execute your Ray task remotely, you must use a `.remote()` call.\n",
    "Ray executes remote tasks asynchronously, even on a local cluster.\n",
    "The items in the `object_references` list in the code snippet do not directly contain the results.\n",
    "If you check the Python type of the first item using `type(object_references[0])`,\n",
    "you see that it is actually an `ObjectRef`.\n",
    "These object references correspond to _futures_ for which you need to request the result.\n",
    "The call [ray.get(...)](https://docs.ray.io/en/latest/ray-core/api/doc/ray.get.html#ray.get) is for requesting the result. Whenever you call remote on a Ray task,\n",
    "it immediately returns one or more object references.\n",
    "Consider Ray tasks as the primary way of creating objects.\n",
    "The following section is an example that links multiple tasks together and allows\n",
    "Ray to pass and resolve the objects between them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2373ddd9",
   "metadata": {},
   "source": [
    "Let's review the previous steps.\n",
    "You started with a Python function, then decorated it with `@ray.remote`, making the function a Ray task.\n",
    "Instead of directly calling the original function in the code, you called `.remote(...)` on the Ray task.\n",
    "Finally, you retrieved the results from the Ray cluster using `.get(...)`.\n",
    "Consider creating a Ray task from one of your own functions as an additional exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c834505",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e008a500",
   "metadata": {},
   "source": [
    "Let's review the performance gain from using Ray tasks.\n",
    "On most laptops the runtime is around 0.71 seconds,\n",
    "which is slightly more than the slowest subtask, which is 0.7 seconds.\n",
    "You can further improve the program by leveraging more of Ray’s API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54f53644",
   "metadata": {},
   "source": [
    "### Object Stores\n",
    "\n",
    "The retrieve definition directly accesses items from the `database`. While this works well on a local Ray cluster, consider how it functions on an actual cluster with multiple computers.\n",
    "A Ray cluster has a head node with a driver process and multiple worker nodes with worker processes executing tasks.\n",
    "In this scenario the database is only defined on the driver, but the worker processes need access to it to run the retrieve task.\n",
    "Ray's solution for sharing objects between the driver and workers or between workers is to use\n",
    "the `ray.put` function to place the data into Ray's distributed object store.\n",
    "In the `retrieve_task` definition, you can add a `db` argument to pass later as the `db_object_ref` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da66a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_object_ref = ray.put(database)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def retrieve_task(item, db):\n",
    "    time.sleep(item / 10.)\n",
    "    return item, db[item]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72f37eb4",
   "metadata": {},
   "source": [
    "By using the object store, you allow Ray to manage data access throughout the entire cluster.\n",
    "Although the object store involves some overhead, it improves performance for larger datasets.\n",
    "This step is crucial for a truly distributed environment.\n",
    "\n",
    "#### YouTry\n",
    "\n",
    "Rerun the example with the `retrieve_task` function to confirm that it executes as you expect.\n",
    "You can do this by replacing XXXX in the cell below with the appropriate argument from Ray's distributed object store you just created. You should get an output similar to the following:\n",
    "\n",
    "```\n",
    "Runtime: 0.72 seconds, data:\n",
    "(0, 'Learning')\n",
    "(1, 'Ray')\n",
    "(2, 'Flexible')\n",
    "(3, 'Distributed')\n",
    "(4, 'Python')\n",
    "(5, 'for')\n",
    "(6, 'Machine')\n",
    "(7, 'Learning')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b5cc2-1dfa-4a37-836a-0b87227285d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "object_references = [\n",
    "    retrieve_task.remote(item, XXXX ) for item in range(8)\n",
    "]\n",
    "data = ray.get(object_references)\n",
    "print_runtime(data, start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "453e312f",
   "metadata": {},
   "source": [
    "### Non-blocking calls\n",
    "\n",
    "In the previous section, you used `ray.get(object_references)` to retrieve results.\n",
    "This call blocks the driver process until all results are available.\n",
    "This dependency can cause problems if each database item takes several minutes to process.\n",
    "More efficiency gains are possible if you allow the driver process to perform other tasks while waiting for results,\n",
    "and to process results as they are completed rather than waiting for all items to finish.\n",
    "Additionally, if one of the database items cannot be retrieved due to an issue like a deadlock in the database connection,\n",
    "the driver hangs indefinitely.\n",
    "To prevent indefinite hangs, set reasonable `timeout` values when using the `wait` function.\n",
    "For example, if you want to wait less than ten times the time of the slowest data retrieval task,\n",
    "use the `wait` function to stop the task after that time has passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75da06ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.01 seconds, data:\n",
      "(0, 'Learning')\n",
      "Runtime: 0.11 seconds, data:\n",
      "(1, 'Ray')\n",
      "Runtime: 0.21 seconds, data:\n",
      "(2, 'Flexible')\n",
      "Runtime: 0.31 seconds, data:\n",
      "(3, 'Distributed')\n",
      "Runtime: 0.41 seconds, data:\n",
      "(4, 'Python')\n",
      "Runtime: 0.51 seconds, data:\n",
      "(5, 'for')\n",
      "Runtime: 0.61 seconds, data:\n",
      "(6, 'Machine')\n",
      "Runtime: 0.71 seconds, data:\n",
      "(7, 'Learning')\n",
      "Runtime: 0.72 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "object_references = [\n",
    "    retrieve_task.remote(item, db_object_ref) for item in range(8)\n",
    "]\n",
    "all_data = []\n",
    "\n",
    "while len(object_references) > 0:\n",
    "    finished, object_references = ray.wait(\n",
    "        object_references, timeout=7.0\n",
    "    )\n",
    "    data = ray.get(finished)\n",
    "    print_runtime(data, start)\n",
    "    all_data.extend(data)\n",
    "\n",
    "print_runtime(all_data, start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf6f00c3",
   "metadata": {},
   "source": [
    "Instead of printing the results, you can use the retrieved values\n",
    "within the `while` loop to initiate new tasks on other workers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a9f6be5",
   "metadata": {},
   "source": [
    "### Task dependencies\n",
    "\n",
    "You may want to perform an additional processing task on the retrieved data. For example, \n",
    "use the results from the first retrieval task to query other related data from the same database (perhaps from a different table).\n",
    "The code below sets up this follow-up task and executes both the `retrieve_task` and `follow_up_task` in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5734bb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 'Learning'), (1, 'Ray'))\n",
      "((2, 'Flexible'), (3, 'Distributed'))\n",
      "((4, 'Python'), (5, 'for'))\n",
      "((6, 'Machine'), (7, 'Learning'))\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def follow_up_task(retrieve_result):\n",
    "    original_item, _ = retrieve_result\n",
    "    follow_up_result = retrieve(original_item + 1)\n",
    "    return retrieve_result, follow_up_result\n",
    "\n",
    "\n",
    "retrieve_refs = [retrieve_task.remote(item, db_object_ref) for item in [0, 2, 4, 6]]\n",
    "follow_up_refs = [follow_up_task.remote(ref) for ref in retrieve_refs]\n",
    "\n",
    "result = [print(data) for data in ray.get(follow_up_refs)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e4a6945",
   "metadata": {},
   "source": [
    "If you're unfamiliar with asynchronous programming, this example may not be particularly impressive.\n",
    "However, at second glance it might be surprising that the code runs at all.\n",
    "The code appears to be a regular Python function with a few list comprehensions.\n",
    "\n",
    "The function body of `follow_up_task` expects a Python tuple for its input argument `retrieve_result`.\n",
    "However, when you use the `[follow_up_task.remote(ref) for ref in retrieve_refs]` command,\n",
    "you are not passing tuples to the follow-up task.\n",
    "Instead, you are using the `retrieve_refs` to pass in Ray object references.\n",
    "\n",
    "Behind the scenes, Ray recognizes that the `follow_up_task` needs actual values,\n",
    "so it _automatically_ uses the `ray.get` function to resolve these futures.\n",
    "Additionally, Ray creates a dependency graph for all the tasks and executes them in a way that respects their dependencies.\n",
    "You don't have to explicitly tell Ray when to wait for a previous task to be completed––it infers the order of execution.\n",
    "This feature of the Ray object store is useful because you avoid copying large intermediate values\n",
    "back to the driver by passing the object references to the next task and letting Ray handle the rest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8722673",
   "metadata": {},
   "source": [
    "The next steps in the process are only scheduled once the tasks specifically designed to retrieve information are completed.\n",
    "In fact, if `retrieve_refs` was called `retrieve_result`, you might not have noticed this crucial and intentional naming nuance. Ray allows you to concentrate on your work rather than the technicalities of cluster computing.\n",
    "The dependency graph for the two tasks looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b8e46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "![Task dependency](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_02/task_dependency.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4001edb",
   "metadata": {},
   "source": [
    "### Ray Actors\n",
    "\n",
    "This example covers one more significant aspect of Ray Core.\n",
    "Up until this step, everything is essentially a function.\n",
    "You used the `@ray.remote` decorator to make certain functions remote, but aside from that, you only used standard Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7a6e69",
   "metadata": {},
   "source": [
    "If you want to keep track of how often the database is being queried, you could count the results of the retrieve tasks.\n",
    "However, is there a more efficient way to do this? Ideally, you want to track this in a distributed manner that can handle a large amount of data.\n",
    "Ray provides a solution with actors, which run stateful computations on a cluster and can also communicate with each other.\n",
    "Similar to how you create Ray tasks using decorated functions, create Ray actors using decorated Python classes.\n",
    "Therefore, you can create a simple counter using a Ray actor to track the number of database calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "717df7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DataTracker:\n",
    "    def __init__(self):\n",
    "        self._counts = 0\n",
    "\n",
    "    def increment(self):\n",
    "        self._counts += 1\n",
    "\n",
    "    def counts(self):\n",
    "        return self._counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e003cc6",
   "metadata": {},
   "source": [
    "The DataTracker class becomes an actor when you give it the `ray.remote` decorator. This actor is capable of tracking state,\n",
    "such as a count, and its methods are Ray actor tasks that you can invoke in the same way as functions using `.remote()`.\n",
    "Modify the retrieve_task to incorporate this actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6843b8d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Learning'), (1, 'Ray'), (2, 'Flexible'), (3, 'Distributed'), (4, 'Python'), (5, 'for'), (6, 'Machine'), (7, 'Learning')]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-19 03:08:00,219 E 71 27010] core_worker.cc:925: :info_message: Attempting to recover 1 lost objects by resubmitting their tasks or setting a new primary location from existing copies. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def retrieve_tracker_task(item, tracker, db):\n",
    "    time.sleep(item / 10.)\n",
    "    tracker.increment.remote()\n",
    "    return item, db[item]\n",
    "\n",
    "\n",
    "tracker = DataTracker.remote()\n",
    "\n",
    "object_references = [\n",
    "    retrieve_tracker_task.remote(item, tracker, db_object_ref) for item in range(8)\n",
    "]\n",
    "data = ray.get(object_references)\n",
    "\n",
    "print(data)\n",
    "print(ray.get(tracker.counts.remote()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae886162",
   "metadata": {},
   "source": [
    "As expected, the outcome of this calculation is 8.\n",
    "Although you don't need actors to perform this calculation, this demonstrates a way to maintain state across the cluster, possibly involving multiple tasks.\n",
    "In fact, you could pass the actor into any related task or even into the constructor of a different actor.\n",
    "The Ray API is flexible, allowing for limitless possibilities.\n",
    "It's rare for distributed Python tools to allow for stateful computations,\n",
    "which is especially useful for running complex distributed algorithms such as reinforcement learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8bd0f5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this example, you only used six API methods.\n",
    "These included `ray.init()` to initiate the cluster, `@ray.remote` to transform functions and classes into tasks and actors,\n",
    "`ray.put()` to transfer values into Ray's object store, and `ray.get()` to retrieve objects from the cluster.\n",
    "Additionally, you used `.remote()` on actor methods or tasks to execute code on the cluster, and `ray.wait` to prevent blocking calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d936caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d8693e9",
   "metadata": {},
   "source": [
    "The Ray API consists of more than these six calls, but these six are powerful, if you're just starting out.\n",
    "To summarize more generally, the methods are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb14bd",
   "metadata": {},
   "source": [
    "- `ray.init()`: Initializes your Ray cluster. Pass in an address to connect to an existing cluster.\n",
    "- `@ray.remote`: Turns functions into tasks and classes into actors.\n",
    "- `ray.put()`: Puts values into Ray’s object store.\n",
    "- `ray.get()`: Gets values from the object store. Returns the values you’ve put there or that were computed by a task or actor.\n",
    "- `.remote()`: Runs actor methods or tasks on your Ray cluster and is used to instantiate actors.\n",
    "- `ray.wait()`: Returns two lists of object references, one with finished tasks we’re waiting for and one with unfinished tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ddcef5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Want to learn more?\n",
    "\n",
    "This example is a simplified version of the Ray Core walkthrough of [our \"Learning Ray\" book](https://maxpumperla.com/learning_ray/).\n",
    "If you liked it, check out the [Ray Core Examples Gallery](https://docs.ray.io/en/latest/ray-core/examples/overview.html) or some of the ML workloads in our [Use Case Gallery](https://docs.ray.io/en/latest/ray-overview/use-cases.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008f94e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
