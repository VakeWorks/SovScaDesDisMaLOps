{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88bf0d1",
   "metadata": {},
   "source": [
    "# An Overview of Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755b31b",
   "metadata": {},
   "source": [
    "One of the reasons we need efficient distributed computing is that we’re collecting\n",
    "ever more data with a large variety at increasing speeds. The storage systems, data\n",
    "processing and analytics engines that have emerged in the last decade are crucially\n",
    "important to the success of many companies. Interestingly, most “big data” technologies\n",
    "are built for and operated by (data) engineers, that are in charge of data\n",
    "collection and processing tasks. The rationale is to free up data scientists to do\n",
    "what they’re best at. As a data science practitioner you might want to focus on training\n",
    "complex machine learning models, running efficient hyperparameter selection,\n",
    "building entirely new and custom models or simulations, or serving your models to\n",
    "showcase them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cebcd0",
   "metadata": {},
   "source": [
    "At the same time, it might be inevitable to scale these workloads to a compute\n",
    "cluster. To do that, the distributed system of your choice needs to support all of these\n",
    "fine-grained “big compute” tasks, potentially on specialized hardware. Ideally, it also\n",
    "fits into the big data tool chain you’re using and is fast enough to meet your latency\n",
    "requirements. In other words, distributed computing has to be powerful and flexible\n",
    "enough for complex data science workloads — and Ray can help you with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00480805",
   "metadata": {},
   "source": [
    "Python is likely the most popular language for data science today, and it’s certainly\n",
    "the one we find the most useful for our daily work. By now it’s over 30 years old,\n",
    "but has a still growing and active community. The rich [PyData ecosystem](https://\n",
    "pydata.org/) is an essential part of a data scientist’s toolbox. How can you make sure\n",
    "to scale out your workloads while still leveraging the tools you need? That’s a difficult\n",
    "problem, especially since communities can’t be forced to just toss their toolbox, or\n",
    "programming language. That means distributed computing tools for data science\n",
    "have to be built for their existing community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2dc7e",
   "metadata": {},
   "source": [
    "Every chapter of this book has an executable notebook that you can run. If you want run the code while following this chapter, you can run this notebook locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7dd72",
   "metadata": {},
   "source": [
    "For this chapter you need to install the following dependencies. We guide you through each dependency and when you need it later on, but if you're impatient you can install them all right now:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5a63e",
   "metadata": {},
   "source": [
    "## What is Ray?\n",
    "\n",
    "Ray is a great computing framework for the Python data science community because it is flexible and distributed, making it easy to use and understand. It allows you to efficiently parallelize Python programs on your own computer and run them on a cluster without much modification. Additionally, its high-level libraries are easy to set up and can be used together smoothly, and some of them, such as the reinforcement learning library, have a promising future as standalone projects. Even though its core is written in C++, Ray has always been focused on Python and integrates well with many important data science tools. It also has a expanding ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795bed4",
   "metadata": {},
   "source": [
    "Ray is not the first framework for distributed Python, nor will it be the last, but it stands out for its ability to handle custom machine learning tasks with ease. Its various modules work well together, allowing for the flexible execution of complex workloads using familiar Python tools. This book aims to teach how to use Ray to effectively utilize distributed Python for machine learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba089d",
   "metadata": {},
   "source": [
    "Programming distributed systems can be challenging because it requires specific skills and experience. While these systems are designed to be efficient and allow users to focus on their tasks, they often have [\"leaky abstractions\"](https://www.joelonsoftware.com/2002/11/11/thelaw-of-leaky-abstractions) that can make it difficult to get clusters of computers to work as desired. In addition, many software systems require more resources than a single server can provide, and modern systems need to be able to handle failures and offer high availability. This means that applications may need to run on multiple machines or even in different data centers in order to function reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08256e35",
   "metadata": {},
   "source": [
    "Even if you are not very familiar with machine learning (ML) or artificial intelligence (AI), you have probably heard about recent advances in these fields. Some examples of these advances include Deepmind's Alpha-Fold, which is a system for solving the protein folding problem, and OpenAI's Codex, which helps software developers with the tedious parts of their job. It is commonly known that ML systems require a lot of data to be trained and that ML models tend to become larger. OpenAI has demonstrated that the amount of computing power needed to train AI models has been increasing exponentially, as shown in their paper \"AI and Compute.\" In their study, the operations needed for AI systems were measured in petaflops (thousands of trillion operations per second) and have doubled every 3.4 months since 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a010dd",
   "metadata": {},
   "source": [
    "While Moore's Law suggests that computer transistors will double every two years, the use of distributed computing in machine learning can significantly increase the speed at which tasks are completed. While distributed computing may be seen as challenging, it would be beneficial to develop abstractions that allow for code to run on clusters without constantly considering individual machines and their interactions. By focusing specifically on AI workloads, it may be possible to make distributed computing more accessible and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fcd87",
   "metadata": {},
   "source": [
    "Researchers at RISELab at UC Berkeley developed Ray to improve the efficiency of their workloads by distributing them. These workloads were flexible in nature and did not fit into existing frameworks. Ray was also designed to handle the distribution of the work and allow researchers to focus on their work without worrying about the specifics of their compute cluster. It was created with a focus on high-performance and diverse workloads, and allows researchers to use their preferred Python tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28aaa68",
   "metadata": {},
   "source": [
    "### Design Philosophy\n",
    "\n",
    "Ray was created with a focus on certain design principles. Its API aims to be straightforward and applicable to a wide range of situations, while the compute model is designed to be adaptable. Additionally, the system architecture is optimized for speed and the ability to handle increasing workloads. Let's delve into these points further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dea857",
   "metadata": {},
   "source": [
    "#### Simplicity and abstraction\n",
    "\n",
    "Ray's API is not only simple to use, but it is also intuitive and easy to learn, as you will see in Chapter 2. Whether you want to use all the CPU cores on your laptop or leverage all the machines in your cluster, you can do so with minimal changes to your code. Ray handles task distribution and coordination behind the scenes, allowing you to focus on your work rather than worrying about the mechanics of distributed computing. Additionally, the API is very flexible and can easily be integrated with other tools. For example, Ray actors can interact with other distributed Python workloads, making it a useful \"glue code\" for connecting different systems and frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f1f1a",
   "metadata": {},
   "source": [
    "#### Flexibility and heterogeneity\n",
    "\n",
    "Ray's API is created to allow users to easily write flexible and modular code for artificial intelligence tasks, especially those involving reinforcement learning. As long as the workload can be expressed in Python, it can be distributed using Ray. However, it is important to ensure that sufficient resources are available and to consider what should be distributed. Ray does not impose any limitations on what can be done with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83621e6c",
   "metadata": {},
   "source": [
    "Ray is able to handle a variety of different computational tasks. For example, when working on a complex simulation, it is common for there to be different steps that take different amounts of time to complete. Some may take a long time while others only take a few milliseconds. Ray is able to efficiently schedule and execute these tasks, even if they need to be run in parallel. Additionally, Ray's framework allows for dynamic execution, which is helpful when subsequent tasks depend on the outcome of an earlier task. Overall, Ray provides flexibility in managing heterogeneous workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637aa16",
   "metadata": {},
   "source": [
    "It is important to be able to adapt your resource usage and Ray allows for the use of different types of hardware. For example, certain tasks may require the use of a GPU while others may perform better on a CPU. Ray gives you the ability to choose the most appropriate hardware for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752190b",
   "metadata": {},
   "source": [
    "#### Speed and scalability\n",
    "\n",
    "One of the key features of Ray is its speed. It can handle millions of tasks per second with minimal latency, making it an efficient choice for distributed systems. Additionally, Ray is effective at distributing and scheduling tasks across a compute cluster, and it does so in a way that is fault-tolerant. Its auto-scaler can adjust the number of machines in the cluster to match current demand, which helps to minimize costs and ensure there are enough resources available to run workloads. In the event of failures, Ray is designed to recover quickly, further contributing to its overall speed. While we will delve into the specifics of Ray's architecture later on, for now, let's focus on how it can be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf37d6",
   "metadata": {},
   "source": [
    "### Core, Libraries and Ecosystem\n",
    "\n",
    "Now that you are aware of the purpose and goals behind the creation of Ray, let's examine the three layers of the system. While there may be other ways to classify these layers, the approach used in this book is the most logical and understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe95e4",
   "metadata": {},
   "source": [
    "1. A low-level, distributed computing framework for Python with a concise core API and tooling for cluster deployment called Ray Core.\n",
    "2. A set of high-level libraries for built and maintained by the creators of Ray. This includes the so-called Ray AI Runtime (AIR) to use these libraries with a unified API in common machine learning workloads.\n",
    "3. A growing ecosystem of integrations and partnerships with other notable\n",
    "projects, which span many aspects of the first two layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45267d",
   "metadata": {},
   "source": [
    "There are several layers to explore in this chapter. The core of Ray's engine, with its API at the center, serves as the foundation for everything else. The data science libraries in Ray build on top of this core and offer a specialized interface. Many data scientists will use these libraries directly, while those working in ML or platform engineering may focus on creating tools that extend the Ray Core API. Ray AIR serves as a connector between the various Ray libraries and provides a consistent framework for handling common AI tasks. Additionally, there are a increasing number of third-party integrations available for Ray that can be utilized by experienced practitioners. We will examine each of these layers in more detail.\n",
    "\n",
    "Below is a quick preview of what libraries and integrations each layer consists of. Maybe you already spot a few of your favorite tools from the ecosystem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551fa5c",
   "metadata": {},
   "source": [
    "![Ray Layers](./images/chapter_01/ray_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4462377",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## A framework for distributed computing\n",
    "\n",
    "At its core, Ray is a distributed computing framework.\n",
    "We'll  provide you with just the basic terminology here, and talk about Ray's\n",
    "architecture in depth in chapter 2.\n",
    "In short, Ray sets up and manages clusters of computers so that you can run\n",
    "distributed tasks on them.\n",
    "A ray cluster consists of nodes that are connected to each other via a network.\n",
    "You program against the so-called _driver_, the program root, which lives on\n",
    "the _head node_.\n",
    "The driver can run _jobs_, that is a collection of tasks, that are run on the nodes\n",
    "in the cluster.\n",
    "Specifically, the individual tasks of a job are run on _worker_ processes on\n",
    "worker nodes_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c2640",
   "metadata": {},
   "source": [
    "![Ray cluster](./images/chapter_01/simple_cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668e1ae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "What's interesting is that a Ray cluster can also be a _local cluster_, i.e. a cluster\n",
    "consisting just of your own computer.\n",
    "In this case, there's just one node, namely the head node, which has the driver\n",
    "process and some worker processes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de3a35",
   "metadata": {},
   "source": [
    "By running just two lines of code, you can set up a Ray cluster on your local machine. This cluster can take advantage of all the cores on your computer as worker processes. Currently, your Ray cluster isn't doing much, but that will change in the following section. The init function used to initiate the cluster is one of just six fundamental API calls that you will delve into in Chapter 2. Overall, the Ray Core API is straightforward and easy to use, but since it is also a lower-level interface, it takes time to create more complex examples with it. Chapter 2 includes a detailed first example to introduce you to the Ray Core API, and in Chapter 3 you will see how to build a more advanced Ray application for reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfedfee",
   "metadata": {},
   "source": [
    "In the above example, you did not provide any arguments when calling the `ray.init(...)` function. If you wanted to use Ray on a real cluster, you would need to include more arguments in this init call, which is known as the Ray Client. The Ray Client is used to connect to an existing Ray cluster and interact with it. If you are interested in learning more about using the Ray Client to connect to your production clusters, you can refer to the [Ray documentation](https://docs.ray.io/en/latest/cluster/ray-client.html). Keep in mind that working with compute clusters can be complex, and there are many options for deploying Ray applications on them. For example, you can use cloud providers like AWS, GCP, or Azure to host your Ray clusters, or you can set up your own hardware or use tools like Kubernetes. We will revisit the topic of scaling workloads with Ray Clusters in Chapter 9, after discussing some specific applications of Ray in earlier chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cab30",
   "metadata": {},
   "source": [
    "Before moving on the Ray’s higher level libraries, let’s briefly summarize the two\n",
    "foundational components of Ray as a distributed computation framework:\n",
    "\n",
    "- _Ray Clusters_: This component is in charge of allocating resources, creating nodes,\n",
    "and ensuring they are healthy. A good way to get started with Ray Clusters is its\n",
    "dedicated quick start guide (https://docs.ray.io/en/latest/cluster/quickstart.html).\n",
    "- _Ray Core_: Once your cluster is up and running, you use the Ray Core API\n",
    "that to program against it. You can get started with Ray Core by following the\n",
    "official walk-through (https://docs.ray.io/en/latest/ray-core/walkthrough.html) for\n",
    "this component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c684724",
   "metadata": {},
   "source": [
    "## Ray's Libraries\n",
    "\n",
    "In this section, we will introduce the data science libraries included with Ray. To understand how these libraries can be beneficial to you, it's important to first have a general understanding of what data science entails. With this context in mind, you'll be able to see how Ray's higher-level libraries fit into the larger picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5e6fb",
   "metadata": {},
   "source": [
    "### Ray AIR and the Data Science Workflow\n",
    "\n",
    "The concept of \"data science\" (DS) has undergone significant changes in recent years, and you can find various definitions of the term online, some more useful than others. However, we believe that data science is the practice of using data to gain insights and develop practical applications. It is a field that involves building and understanding things, and is therefore quite practical and applied. In this sense, calling practitioners of this field \"data scientists\" is similar to calling hackers \"computer scientists\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c96d8",
   "metadata": {},
   "source": [
    "Data science involves a series of steps that involve identifying and gathering the necessary data, processing it, creating models, and implementing solutions. While machine learning may be a part of this process, it is not always necessary. If machine learning is included, there may be additional steps involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925fab2",
   "metadata": {},
   "source": [
    "- _Data Processing_: To use machine learning effectively, you must prepare the data in a way that the ML model can understand. This process, called feature engineering, involves selecting and transforming the data that will be input into the model. It can be a challenging task, so it is helpful to have access to reliable tools to assist with it.\n",
    "- _Model Training_: For machine learning, it is necessary to train your algorithms on data that has been previously processed. This involves selecting the appropriate algorithm for the task at hand. Having a diverse range of algorithms to choose from can also be beneficial.\n",
    "- _Hyperparameter Tuning_: During the process of training a machine learning model, certain parameters can be fine-tuned in order to improve its performance. In addition to these model parameters, there are also hyperparameters that can be adjusted before training begins. The proper adjustment of these hyperparameters can significantly impact the effectiveness of the final machine learning model. Fortunately, there are tools available to assist with the process of optimizing these hyperparameters.\n",
    "- _Model Serving_: The deployment of trained models is necessary in order to provide access to them for those who need it. This process, known as serving a model, involves making it available through various means, such as using simple HTTP servers in prototypes or specialized software packages specifically designed for serving ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f2d2d",
   "metadata": {},
   "source": [
    "It is important to note that this list is not exhaustive and there is more to consider when building machine learning applications. Nonetheless, it is undeniable that these four steps are critical for the success of a data science project that utilizes machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9d3a9",
   "metadata": {},
   "source": [
    "![Data Science Workflow](./images/chapter_01/ds_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d395aa2",
   "metadata": {},
   "source": [
    "Ray has created dedicated libraries for each of the four ML-specific steps mentioned earlier. These libraries include Ray Datasets for data processing, Ray Train for distributed model training, Ray RLlib for reinforcement learning workloads, Ray Tune for efficient hyperparameter tuning, and Ray Serve for serving models. It is important to note that all of these libraries are distributed by design, as that is how Ray is built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faef52c",
   "metadata": {},
   "source": [
    "Additionally, it is important to consider that these steps are usually not completed separately but rather as part of a larger process. It is beneficial to have all relevant libraries working smoothly together and to have a uniform API throughout the data science process. The Ray AI Runtime (AIR) was designed with this in mind, providing a common runtime and API for experiments and the capability to expand workloads as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40b5e9",
   "metadata": {},
   "source": [
    "![Ray AIR](./images/chapter_01/AIR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918c5a",
   "metadata": {},
   "source": [
    "In this chapter, we will not be discussing the Ray AI Runtime API in depth (more on that can be found in Chapter 10). However, we can provide an overview of the components that contribute to it. Specifically, we will go through each of the DS libraries that make up Ray one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312e12f",
   "metadata": {},
   "source": [
    "### Ray Data\n",
    "The first high-level library of Ray we talk about is called \"Ray Data\".\n",
    "This library contains a data structure aptly called `Dataset`, a multitude of\n",
    "connectors for loading data from various formats and systems,\n",
    "an API for transforming such datasets, a way to build data processing pipelines\n",
    "with them, and many integrations with other data processing frameworks.\n",
    "The `Dataset` abstraction builds on the powerful\n",
    "[Arrow framework](https://arrow.apache.org/).\n",
    "\n",
    "To use Ray Data, you need to install Arrow for Python, for instance by running\n",
    "`pip install pyarrow`.\n",
    "We'll now discuss a simple example that creates a distributed `Dataset` on your\n",
    "local Ray cluster from a Python data structure.\n",
    "Specifically, you'll create a dataset from a Python dictionary containing a\n",
    "string `name` and an integer-valued `data` for `10000` entries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c95752b",
   "metadata": {},
   "source": [
    "Great, ..., but what can you do with that data?\n",
    "The `Dataset` API bets heavily on functional programming, as it is very well suited\n",
    "for data transformations.\n",
    "Even though Python 3 made a point of hiding some of its functional programming\n",
    "capabilities, you're probably\n",
    "familiar with functionality such as `map`, `filter` and others.\n",
    "If not, it's easy enough to pick up.\n",
    "`map` takes each element of your dataset and transforms is into something\n",
    "else, in parallel.\n",
    "`filter` removes data points according to a boolean filter function.\n",
    "And the slightly more elaborate `flat_map` first maps values similarly to `map`,\n",
    "but then also \"flattens\" the result.\n",
    "For instance, if `map` would produce a list of lists, `flat_map` would flatten out\n",
    "the nested lists and give\n",
    "you just a list.\n",
    "Equipped with these three functional API calls, let's see how easily you can\n",
    "transform your dataset `ds`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db60f0",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Next, we will examine the distributed training abilities of Ray through two libraries. The first library is specifically for reinforcement learning, while the second library is primarily focused on supervised learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a3296",
   "metadata": {},
   "source": [
    "### RL with Ray RLlib\n",
    "\n",
    "We will begin with discussing Ray RLlib for reinforcement learning, a library that utilizes either TensorFlow or PyTorch as its underlying machine learning framework. Both of these frameworks are highly compatible with each other, so you can use whichever one you prefer without sacrificing much in terms of functionality. In this book, we will provide examples using both TensorFlow and PyTorch to give you a comprehensive understanding of how to use Ray with either framework. In this chapter we'll work with TensorFlow, which you can install by simply running the command \"pip install tensorflow\" in your terminal. If you wanted to, you could equally well install PyTorch instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88c28e",
   "metadata": {},
   "source": [
    "RLlib provides a command line tool called `rllib` that can be easily used to run examples. It was already installed when you ran \"pip install 'ray[rllib]'\" earlier. While you will primarily use the Python API for more advanced examples in Chapter 4, this tool allows you to quickly try out RL experiments using RLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a7dbc",
   "metadata": {},
   "source": [
    "We will consider a classic control problem in which we try to balance a pole on a cart. Imagine that the pole is attached to the cart at a joint and is subject to the force of gravity. The cart is able to move along a frictionless track and we can give it a push to the left or right with a fixed force. If we do this properly, the pole should remain upright. For each time step in which the pole does not fall, we receive a reward of 1. Our goal is to collect as many rewards as possible and we want to see if we can use a reinforcement learning algorithm to help us achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5432ed",
   "metadata": {},
   "source": [
    "![Cartpole Env](./images/chapter_01/cartpole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7c019",
   "metadata": {},
   "source": [
    "Our goal is to train a reinforcement learning agent that can perform two actions: pushing to the left or to the right, observe the consequences of these actions, and learn from the experience to maximize the reward. To achieve this using Ray RLlib, we can utilize a \"tuned example,\" which is a pre-set algorithm that works effectively for a specific problem. These examples can be easily run with a single command and RLlib offers a variety of them, which can be viewed by using this command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35125e",
   "metadata": {},
   "source": [
    "### Ray Tune\n",
    "Naming things is hard, but the Ray team hit the spot with _Ray Tune_, which you can\n",
    "use to tune all\n",
    "sorts of parameters.\n",
    "Specifically, it was built to find good hyperparameters for machine learning models.\n",
    "The typical setup is as follows:\n",
    "\n",
    "- You want to run an extremely computationally expensive training function. In ML it's not uncommon\n",
    "  to run training procedures that take days, if not weeks, but let's say you're dealing with just a couple of minutes.\n",
    "- As result of training, you compute a so-called objective function. Usually you either want to maximize\n",
    "  your gains or minimize your losses in terms of performance of your experiment.\n",
    "- The tricky bit is that your training function might depend on certain parameters,\n",
    "  hyperparameters, that influence the value of your objective function.\n",
    "- You may have a hunch what individual hyperparameters should be, but tuning them all can be difficult.\n",
    "  Even if you can restrict these parameters to a sensible range, it's usually prohibitive to test a wide\n",
    "  range of combinations. Your training function is simply too expensive.\n",
    "\n",
    "What can you do to efficiently sample hyperparameters and get \"good enough\" results on your objective?\n",
    "The field concerned with solving this problem is called _hyperparameter optimization_ (HPO), and Ray Tune has\n",
    "an enormous suite of algorithms for tackling it.\n",
    "Let's look at a first example of Ray Tune used for the situation we just explained.\n",
    "The focus is yet again on Ray and its API, and not on a specific ML task (which we simply simulate for now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3298b6",
   "metadata": {},
   "source": [
    "We do a so-called grid search over all possible parameter combinations. As we explicitly\n",
    "pass in five possible values for both x and y that’s a total of 25 combinations\n",
    "that get fed into the training function. These combinations are evaluated through the training function, which includes a 10 second sleep time. Without Ray's ability to parallelize the process, testing all of these combinations would take more than four minutes. However, on my laptop, this experiment only takes around 35 seconds to complete. The duration may vary depending on the device used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab1adf",
   "metadata": {},
   "source": [
    "If each training run took several hours, and there were 20 hyperparameters to consider instead of just two, it would not be practical to use grid search. This is especially true if you do not have a good idea of what range the parameters should be in. In these cases, you will need to use more advanced HPO methods like those offered by Ray Tune, which we will discuss in Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b0c80",
   "metadata": {},
   "source": [
    "### Ray Serve\n",
    "\n",
    "The last of Ray's high-level libraries we'll discuss specializes on model serving and is simply called _Ray Serve_.\n",
    "To see an example of it in action, you need a trained ML model to serve.\n",
    "Luckily, nowadays you can find many interesting models on the internet that have already been trained for you.\n",
    "For instance, _Hugging Face_ has a variety of models available for you to download directly in Python.\n",
    "The model we'll use is a language model called _GPT-2_ that takes text as input and produces text to\n",
    "continue or complete the input.\n",
    "For example, you can prompt a question and GPT-2 will try to complete it.\n",
    "\n",
    "Serving such a model is a good way to make it accessible.\n",
    "You may not now how to load and run a TensorFlow model on your computer, but you do now how\n",
    "to ask a question in plain English.\n",
    "Model serving hides the implementation details of a solution and lets users focus on providing\n",
    "inputs and understanding outputs of a model.\n",
    "\n",
    "To proceed, make sure to run `pip install transformers` to install the Hugging Face library\n",
    "that has the model we want to use.\n",
    "With that we can now import and start an instance of Ray's `serve` library, load and deploy a GPT-2\n",
    "model and ask it for the meaning of life, like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab453063",
   "metadata": {},
   "source": [
    "This is the end of our overview of the data science libraries within the second layer of Ray. These libraries, which we have discussed in this chapter, are all based on the Ray Core API. It is fairly simple to create new extensions for Ray, and there are a few more that we are unable to cover in this book. For example, the Ray Workflows library (https://docs.ray.io/en/latest/workflows/index.html) allows users to define and run long-term applications using Ray. Before we conclude this chapter, let's briefly examine the third layer of Ray, which is the expanding ecosystem surrounding the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a41a",
   "metadata": {},
   "source": [
    "## The Ray Ecosystem\n",
    "\n",
    "Ray's libraries are powerful and should be discussed in more detail in the book. Although they are very useful for data science work, we don't want to give the impression that they are the only thing you need from now on. The most successful frameworks are those that work well with other solutions and ideas. It is better to concentrate on your strengths and use other tools to fill any gaps in your solution, which Ray does well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b073dd4",
   "metadata": {},
   "source": [
    "Throughout the book, we will be discussing various libraries that have been built on top of Ray. Additionally, Ray has integrations with existing tools like Spark, Dask, and Pandas. For instance, you can use Ray Datasets, a data loading and compute library, with your existing project that utilizes data processing engines like Spark or Dask. Additionally, you can run the entire Dask ecosystem on a Ray cluster with the Dask-on-Ray scheduler or use the Spark on Ray project to integrate your Spark workloads with Ray. The Modin project also offers a distributed replacement for Pandas dataframes that utilizes Ray or Dask as the distributed execution engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba65e3",
   "metadata": {},
   "source": [
    "Ray's approach is to integrate with various tools rather than trying to replace them, while still providing access to its own native library called Ray Datasets. This will be explored in more detail later in Chapter 11. It's noteworthy that many of the Ray libraries have the ability to seamlessly integrate with other tools as backends, often by creating common interfaces rather than establishing new standards. These interfaces enable you to perform tasks in a distributed manner, something that many of the backends may not offer or may not offer to the same degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e88155",
   "metadata": {},
   "source": [
    "For example, Ray RLlib and Train both utilize the capabilities of TensorFlow and PyTorch. Additionally, Ray Tune allows for the use of a variety of HPO tools, such as Hyperopt, Optuna, Nevergrad, Ax, and SigOpt, among others. These tools are not automatically distributed, but Tune brings them together in a unified interface for distributed tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7279b0",
   "metadata": {},
   "source": [
    "![Ray Layers](./images/chapter_01/ray_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbc381-8c30-412b-9327-4fe461d814dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
