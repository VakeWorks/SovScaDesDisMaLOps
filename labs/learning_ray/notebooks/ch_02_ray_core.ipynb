{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdddbae",
   "metadata": {},
   "source": [
    "# Getting Started with Ray Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d0ecd",
   "metadata": {},
   "source": [
    "Many of Ray’s concepts can be explained with a good example, so that’s exactly what\n",
    "we’ll do. As before, you can follow this example by typing the code yourself (which\n",
    "is highly recommended), or by following the notebook for this chapter.\n",
    "\n",
    "This notebook has been modified for pedagogical reasons from the original notebook in learning_ray for the dockerized environment.\n",
    "\n",
    "## Install Ray\n",
    "\n",
    "Install Ray with the following command if you have not done so already.\n",
    "\n",
    "If you are running this inside the provided docker container with ray and jupyter already installed. Skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6115afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install \"ray==2.2.0\" # version-specific for original notebooks in learning_ray\n",
    "# ! pip install ray # for latest ray version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4c40f-4edc-411a-8bb8-2d50b7e8b231",
   "metadata": {},
   "source": [
    "## Initializing a Ray Cluster \n",
    "\n",
    "We will generally have to chose from one of these three options in our dockerized environement:\n",
    "\n",
    "1. We want to create a new ray cluster for this notebook and leave any other clusters, if they exist alone\n",
    "    - this can consume more resources, but in this case we can use\n",
    "      - `ray.init(dashboard_host='0.0.0.0')`  \n",
    "2. We want to stop any existing ray clusters and start a new ray cluster for this notebook\n",
    "    - use `! ray stop` to stop ray any active clusters if they exist and then `ray.init(dashboard_host='0.0.0.0')`\n",
    "3. We want to connect to an existing and possibly specific ray cluster\n",
    "    - we can use `! ray status` to check is any ray cluster is active.\n",
    "    - if one ray cluster is active from above command and we want to connect to it then we can use\n",
    "      - `ray.init(address=\"auto\",dashboard_host='0.0.0.0')`\n",
    "    - if more than one ray cluster is active then `! ray status` gives something like:\n",
    "      - `ConnectionError: Found multiple active Ray instances: {'172.17.0.2:53885', '172.17.0.2:65360'}. Please specify the one to connect to by setting the `--address` flag or `RAY_ADDRESS` environment variable.`\n",
    "      - then find status of a specific ray cluster using: `! ray status --address='172.17.0.2:53885'`\n",
    "      - you can connect to it using `ray.init(address='172.17.0.2:53885',dashboard_host='0.0.0.0')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db69b5e9-a18f-4e00-9861-aa220657cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.is_initialized() # check if ray is initialized in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d12d28-01c3-424a-8d7c-4ec6f54ee0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2025-08-28 13:15:41.380700 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Active:\n",
      " 1 node_457760dc2eb6dd7ef62215bdca25f952dfc5ea0b7beaebec937191bf\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Total Usage:\n",
      " 0.0/8.0 CPU\n",
      " 0B/21.07GiB memory\n",
      " 0B/9.03GiB object_store_memory\n",
      "\n",
      "Total Constraints:\n",
      " (no request_resources() constraints)\n",
      "Total Demands:\n",
      " (no resource demands)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray status # check status of any active ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ac7940-b75d-4110-ad5d-9cc2fb29aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ray stop # stop any existing ray cluster and start anew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815a81b4-f4a6-40bc-895c-0ec5c2a2a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 13:17:44,776\tINFO worker.py:1757 -- Connecting to existing Ray cluster at address: 172.17.0.2:51263...\n",
      "2025-08-28 13:17:44,834\tINFO worker.py:1928 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m172.17.0.2:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396913adcf0c4088b75c79b1e6b83e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.9.23</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.0.0.dev0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://172.17.0.2:8265\" target=\"_blank\">http://172.17.0.2:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='172.17.0.2:8265', python_version='3.9.23', ray_version='3.0.0.dev0', ray_commit='f678778f843bd51a441582bf25edc38d99ae5205')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ray.init(dashboard_host='0.0.0.0') # to start a new cluster\n",
    "ray.init(address=\"auto\",dashboard_host='0.0.0.0') # initialize by connecting to existing ray cluster \n",
    "#ray.init(address='172.17.0.2:53885',dashboard_host='0.0.0.0') # connect to a speific ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4238950-6eb3-4890-9272-f010cf441d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '457760dc2eb6dd7ef62215bdca25f952dfc5ea0b7beaebec937191bf',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '172.17.0.2',\n",
       "  'NodeManagerHostname': '12dfbd942909',\n",
       "  'NodeManagerPort': 43259,\n",
       "  'ObjectManagerPort': 37073,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2025-08-28_10-51-50_405814_8275/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2025-08-28_10-51-50_405814_8275/sockets/raylet',\n",
       "  'MetricsExportPort': 61418,\n",
       "  'NodeName': '172.17.0.2',\n",
       "  'RuntimeEnvAgentPort': 47362,\n",
       "  'DeathReason': 0,\n",
       "  'DeathReasonMessage': '',\n",
       "  'alive': True,\n",
       "  'Resources': {'CPU': 8.0,\n",
       "   'node:172.17.0.2': 1.0,\n",
       "   'object_store_memory': 9695442124.0,\n",
       "   'memory': 22622698292.0,\n",
       "   'node:__internal_head__': 1.0},\n",
       "  'Labels': {'ray.io/node-id': '457760dc2eb6dd7ef62215bdca25f952dfc5ea0b7beaebec937191bf'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c327af4b-e8d1-4b49-b93e-b3fc11c18a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': 8.0,\n",
       " 'memory': 22622698292.0,\n",
       " 'object_store_memory': 9695442124.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'node:172.17.0.2': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e02971-05f2-4f2a-8a5d-2806f5b04045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized() # check if ray is initialized in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d6a14-8bd3-40d2-b546-e491cb6381b6",
   "metadata": {},
   "source": [
    "Once the `ray.is_initialized()` evaluates to `true` you can proceed further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d3c98",
   "metadata": {},
   "source": [
    "## A Ray Core Intro\n",
    "\n",
    "After running `ray.init()` in one of the above ways you will see output\n",
    "of the following form. We omit a lot of information in this example output, as that\n",
    "would require you to understand more of Ray’s internals first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75826f4",
   "metadata": {},
   "source": [
    "```\n",
    "... INFO services.py:1263 -- View the Ray dashboard at http://127.0.0.1:8265\n",
    "{'node_ip_address': '192.168.1.41',\n",
    "...\n",
    "'node_id': '...'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c837608",
   "metadata": {},
   "source": [
    "The output of this command indicates that your Ray cluster is functioning properly. As shown in the first line of the output, Ray includes its own dashboard that can be accessed at http://127.0.0.1:8265 or http://localhost:8265 (unless a different port is listed in the output). You can take some time to explore the dashboard, which will display information such as the number of CPU cores available and the total utilization of your current Ray application. If you want to see the resource utilization of your Ray cluster within a Python script, you can use the `ray.cluster_resources()` function. On my computer, this function returns the following output:\n",
    "\n",
    "```\n",
    "{'CPU': 12.0,\n",
    "'memory': 14203886388.0,\n",
    "'node:127.0.0.1': 1.0,\n",
    "'object_store_memory': 2147483648.0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf542ed9",
   "metadata": {},
   "source": [
    "To use the examples in this chapter, you will need to have a running Ray cluster. The purpose of this section is to give you a brief introduction to the Ray Core API, which we will refer to as the Ray API from now on. One of the great things about the Ray API for Python programmers is that it feels very familiar, using concepts such as decorators, functions, and classes. The Ray API is designed to provide a universal programming interface for distributed computing, which is a challenging task, but I believe that Ray succeeds in this by providing abstractions that are easy to understand and use. The Ray engine handles the complicated work behind the scenes, allowing Ray to be used with existing Python libraries and systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52f02a",
   "metadata": {},
   "source": [
    "This chapter begins with a focus on Ray Core because we believe it has the potential to greatly enhance the ease of access to distributed computing. The purpose of this chapter is to give you an in-depth understanding of how Ray functions effectively and how you can grasp its basic concepts. It is important to note that if you are a Python programmer with less experience or prefer to concentrate on more advanced tasks, it may take some time to become familiar with Ray Core. However, we highly recommend taking the time to learn the Ray Core API as it is a fantastic way to start working with distributed computing using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1a3bf",
   "metadata": {},
   "source": [
    "### Your First Ray API Example\n",
    "\n",
    "To give you an example, take the following function which retrieves and processes\n",
    "data from a database. Our dummy database is a plain Python list containing the\n",
    "words of the title of this book. To simulate the idea that accessing and processing data from the database is costly, we have the function `sleep` (pause for a certain amount of time) in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e053331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "database = [\n",
    "    \"Learning\", \"Ray\",\n",
    "    \"Flexible\", \"Distributed\", \"Python\", \"for\", \"Machine\", \"Learning\"\n",
    "]\n",
    "\n",
    "\n",
    "def retrieve(item):\n",
    "    time.sleep(item / 10.)\n",
    "    return item, database[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b518f4f",
   "metadata": {},
   "source": [
    "Our database has eight items in total. If we were to retrieve all items sequentially, how\n",
    "long should that take? For the item with index 5 we wait for half a second `(5 / 10.)`\n",
    "and so on. In total, we can expect a runtime of around `(0+1+2+3+4+5+6+7)/10. =\n",
    "2.8` seconds. Let’s see if that’s what we actually get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0091149",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.80 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "def print_runtime(input_data, start_time):\n",
    "    print(f'Runtime: {time.time() - start_time:.2f} seconds, data:')\n",
    "    print(*input_data, sep=\"\\n\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "data = [retrieve(item) for item in range(8)]\n",
    "print_runtime(data, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa047d",
   "metadata": {},
   "source": [
    "The total time it takes to run the function is 2.82 seconds, but this may vary on your individual computer. It's important to note that our basic Python version is not capable of running this function simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30291db3",
   "metadata": {},
   "source": [
    "You may not have been surprised to hear this, but it's likely that you at least suspected that Python list comprehensions are more efficient in terms of performance. The runtime we measured, which was 2.8 seconds, is actually the worst case scenario. It may be frustrating to see that a program that mostly just \"sleeps\" during its runtime could still be so slow, but the reason for this is due to the Global Interpreter Lock (GIL), which gets enough criticism as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb32d4",
   "metadata": {},
   "source": [
    "#### Ray Tasks\n",
    "\n",
    "It’s reasonable to assume that such a task can benefit from parallelization. Perfectly\n",
    "distributed, the runtime should not take much longer than the longest subtask,\n",
    "namely 7/10. = 0.7 seconds. So, let’s see how you can extend this example to run on\n",
    "Ray. To do so, you start by using the @ray.remote decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e21e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def retrieve_task(item):\n",
    "    return retrieve(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a4062",
   "metadata": {},
   "source": [
    "In this way, the function retrieve_task becomes a so-called Ray task. In essence, a\n",
    "Ray task is a function that gets executed on a different process that it was called from,\n",
    "potentially on a different machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afc80a",
   "metadata": {},
   "source": [
    "It is very convenient to use Ray because you can continue to write your Python code as usual, without having to significantly change your approach or programming style. Using the @ray.remote decorator on your retrieve function is the intended use of decorators, but for the purpose of clarity, we did not modify the original code in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc2e18",
   "metadata": {},
   "source": [
    "To retrieve database entries and measure performance, what changes do you need to make to the code? It's actually not a lot. Here's an overview of the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34697da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.16 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "object_references = [\n",
    "    retrieve_task.remote(item) for item in range(8)\n",
    "]\n",
    "data = ray.get(object_references)\n",
    "print_runtime(data, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4087c",
   "metadata": {},
   "source": [
    "Have you noticed the differences? To execute your Ray task remotely, you must use a `.remote()` call. When tasks are executed remotely, even on your local cluster, Ray does it asynchronously. The items in the object_references list in the previous code snippet do not directly contain the results. In fact, if you check the Python type of the first item using `type(object_references[0])`, you will see that it is actually an `ObjectRef`. These object references correspond to futures that you need to request the result of. This is what the call to `ray.get(...)` is for. Whenever you call remote on a Ray task, it will immediately return one or more object references. In reality, while we introduced `ray.put(...)` first, you should consider Ray tasks as the primary way of creating objects. In the following section, we will provide an example that links multiple tasks together and allows Ray to handle passing and resolving the objects between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373ddd9",
   "metadata": {},
   "source": [
    "We still wish to continue working on this example, but let's take a moment to review what we have done so far. You began with a Python function and decorated it with `@ray.remote`, which made the function a Ray task. Instead of directly calling the original function in your code, you called `.remote(...)` on the Ray task. The final step was to retrieve the results back from your Ray cluster using `.get(...)`. I believe this process is so straightforward that I would bet you could create your own Ray task from another function without referring back to this example. Why don't you give it a try now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008a500",
   "metadata": {},
   "source": [
    "Coming back to our example, by using Ray tasks, what did we gain in terms of\n",
    "performance? On my machine the runtime clocks in at 0.71 seconds, which is just\n",
    "slightly more than the longest subtask, which comes in at 0.7 seconds. That’s great\n",
    "and much better than before, but we can further improve our program by leveraging\n",
    "more of Ray’s API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f53644",
   "metadata": {},
   "source": [
    "#### The Object Store\n",
    "\n",
    "One aspect that may have been noticed is that the retrieve definition involves directly accessing items from the database. While this works well on a local Ray cluster, it is important to consider how this would function on an actual cluster with multiple computers. In a Ray cluster, there is a head node with a driver process and multiple worker nodes with worker processes executing tasks. By default, Ray creates as many worker processes as there are CPU cores on the machine. However, in this scenario the database is defined on the driver only, but the worker processes need access to it to run the retrieve task. Fortunately, Ray has a simple solution for sharing objects between the driver and workers or between workers - using the put function to place the data into Ray's distributed object store. In the `retrieve_task` definition, we explicitly include a `db` argument, which will later be passed the `db_object_ref` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da66a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_object_ref = ray.put(database)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def retrieve_task(item, db):\n",
    "    time.sleep(item / 10.)\n",
    "    return item, db[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f37eb4",
   "metadata": {},
   "source": [
    "By utilizing the object store in this manner, you can allow Ray to manage data access throughout the entire cluster. We will discuss the specifics of how values are transmitted between nodes and within workers when discussing Ray's infrastructure. Although interacting with the object store involves some overhead, it offers improved performance when dealing with larger, more realistic datasets. For now, the crucial aspect is that this step is crucial in a truly distributed environment. If desired, you can try rerunning the previous example with the new `retrieve_task` function to confirm that it still executes as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e312f",
   "metadata": {},
   "source": [
    "#### Non-blocking calls\n",
    "\n",
    "In a previous example, we used ray.get(object_references) to retrieve results. This call blocks the driver process until all results are available. While this may not be an issue if the program finishes in a short amount of time, it could cause problems if each database item takes several minutes to process. In this case, it would be more efficient to allow the driver process to perform other tasks while waiting for results, and to process results as they are completed rather than waiting for all items to be finished. Additionally, if one of the database items cannot be retrieved due to an issue like a deadlock in the database connection, the driver will hang indefinitely. To prevent this, it is a good idea to set reasonable timeouts using the wait function. For example, if we do not want to wait longer than ten times the longest data retrieval task, we can use the wait function to stop the task after that time has passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75da06ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.13 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "Runtime: 0.34 seconds, data:\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "Runtime: 0.55 seconds, data:\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "Runtime: 1.16 seconds, data:\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n",
      "Runtime: 1.16 seconds, data:\n",
      "(0, 'Learning')\n",
      "(1, 'Ray')\n",
      "(2, 'Flexible')\n",
      "(3, 'Distributed')\n",
      "(4, 'Python')\n",
      "(5, 'for')\n",
      "(6, 'Machine')\n",
      "(7, 'Learning')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "object_references = [\n",
    "    retrieve_task.remote(item, db_object_ref) for item in range(8)\n",
    "]\n",
    "all_data = []\n",
    "\n",
    "while len(object_references) > 0:\n",
    "    finished, object_references = ray.wait(\n",
    "        object_references, num_returns=2, timeout=7.0\n",
    "    )\n",
    "    data = ray.get(finished)\n",
    "    print_runtime(data, start)\n",
    "    all_data.extend(data)\n",
    "\n",
    "print_runtime(all_data, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f00c3",
   "metadata": {},
   "source": [
    "Instead of simply printing the results, we could have utilized the values that have been retrieved within the `while` loop to initiate new tasks on other workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f6be5",
   "metadata": {},
   "source": [
    "#### Task dependencies\n",
    "\n",
    "So far, our example program has been straightforward conceptually. It involves one step, which is retrieving a group of items from a database. However, let's say we want to perform an additional processing task on the data after it has been retrieved. For example, we want to use the results from the first retrieval task to query other related data from the same database (for example, from a different table). The code below sets up this follow-up task and executes both the `retrieve_task` and `follow_up_task` in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5734bb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 'Learning'), (1, 'Ray'))\n",
      "((2, 'Flexible'), (3, 'Distributed'))\n",
      "((4, 'Python'), (5, 'for'))\n",
      "((6, 'Machine'), (7, 'Learning'))\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def follow_up_task(retrieve_result):\n",
    "    original_item, _ = retrieve_result\n",
    "    follow_up_result = retrieve(original_item + 1)\n",
    "    return retrieve_result, follow_up_result\n",
    "\n",
    "\n",
    "retrieve_refs = [retrieve_task.remote(item, db_object_ref) for item in [0, 2, 4, 6]]\n",
    "follow_up_refs = [follow_up_task.remote(ref) for ref in retrieve_refs]\n",
    "\n",
    "result = [print(data) for data in ray.get(follow_up_refs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a6945",
   "metadata": {},
   "source": [
    "If you're not experienced with asynchronous programming, this example may not seem particularly impressive. However, I hope to demonstrate that it is somewhat surprising that the code even runs. So, what's the significance of this? Essentially, the code appears to be a regular Python function with a few list comprehensions. The point is that the function body of `follow_up_task` expects a Python tuple for its input argument `retrieve_result`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e0b16",
   "metadata": {},
   "source": [
    "However, when we use the `[follow_up_task.remote(ref) for ref in retrieve_refs]` command, we are not actually passing tuples to the follow-up task at all. Instead, we are using the `retrieve_refs` to pass in Ray object references. \n",
    "\n",
    "Behind the scenes, Ray recognizes that the `follow_up_task` needs actual values, so it will automatically use the `ray.get` function to resolve these futures. Additionally, Ray creates a dependency graph for all of the tasks and executes them in a way that respects their dependencies. This means that we don't have to explicitly tell Ray when to wait for a previous task to be completed - it is able to infer this information on its own. This feature of the Ray object store is particularly useful because it allows us to avoid copying large intermediate values back to the driver by simply passing the object references to the next task and letting Ray handle the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8722673",
   "metadata": {},
   "source": [
    "The next steps in the process will only be scheduled once the tasks specifically designed to retrieve information are completed. Personally, I believe this is a fantastic feature. In fact, if we had named the retrieve_refs task something like retrieve_result, you might not have even noticed this crucial detail. This was intentional, as Ray wants you to concentrate on your work rather than the technicalities of cluster computing. The dependency graph for the two tasks looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b8e46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "![Task dependency](./images/chapter_02/task_dependency.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4001edb",
   "metadata": {},
   "source": [
    "#### Ray Actors\n",
    "\n",
    "Before concluding this example, we should cover one more significant aspect of Ray Core. As you can see in our example, everything is essentially a function. We utilized the `@ray.remote` decorator to make certain functions remote, but besides that, we only used standard Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a6e69",
   "metadata": {},
   "source": [
    "If we want to keep track of how often our database is being queried, we could just count the results of the retrieve tasks. However, is there a more efficient way to do this? Ideally, we want to track this in a distributed manner that can handle a large amount of data. Ray provides a solution with actors, which are used to run stateful computations on a cluster and can also communicate with each other. Similar to how Ray tasks are created using decorated functions, Ray actors are created using decorated Python classes. Therefore, we can create a simple counter using a Ray actor to track the number of database calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717df7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DataTracker:\n",
    "    def __init__(self):\n",
    "        self._counts = 0\n",
    "\n",
    "    def increment(self):\n",
    "        self._counts += 1\n",
    "\n",
    "    def counts(self):\n",
    "        return self._counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e003cc6",
   "metadata": {},
   "source": [
    "The DataTracker class is an actor because it has been given the ray.remote decorator. This actor is capable of tracking state, such as a counter, and its methods are Ray tasks that can be invoked in the same way as functions using .remote(). We can modify the retrieve_task to incorporate this actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6843b8d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Learning'), (1, 'Ray'), (2, 'Flexible'), (3, 'Distributed'), (4, 'Python'), (5, 'for'), (6, 'Machine'), (7, 'Learning')]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def retrieve_tracker_task(item, tracker, db):\n",
    "    time.sleep(item / 10.)\n",
    "    tracker.increment.remote()\n",
    "    return item, db[item]\n",
    "\n",
    "\n",
    "tracker = DataTracker.remote()\n",
    "\n",
    "object_references = [\n",
    "    retrieve_tracker_task.remote(item, tracker, db_object_ref) for item in range(8)\n",
    "]\n",
    "data = ray.get(object_references)\n",
    "\n",
    "print(data)\n",
    "print(ray.get(tracker.counts.remote()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae886162",
   "metadata": {},
   "source": [
    "As expected, the outcome of this calculation is 8. Although we didn't need actors to perform this calculation, it's valuable to have a way to maintain state across the cluster, possibly involving multiple tasks. In fact, we could pass our actor into any related task or even into the constructor of a different actor. The Ray API is very flexible, allowing for limitless possibilities. It's also worth mentioning that it's not common for distributed Python tools to allow for stateful computations like this, making it especially useful for running complex distributed algorithms such as reinforcement learning. This concludes our detailed first example of the Ray API. Let's now try to briefly summarize the Ray API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bd0f5",
   "metadata": {},
   "source": [
    "### Ray Core API Summary\n",
    "\n",
    "Remembering what we did in the previous example, you will see that we only used six API methods. These included `ray.init()` to initiate the cluster, `@ray.remote` to transform functions and classes into tasks and actors, `ray.put()` to transfer values into Ray's object store, and `ray.get()` to retrieve objects from the cluster. Additionally, we used `.remote()` on actor methods or tasks to execute code on our cluster, and `ray.wait` to prevent blocking calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8693e9",
   "metadata": {},
   "source": [
    "Although the Ray API only includes six methods, they are all that you will likely need to use. To make it easier to remember these methods, here's a summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb14bd",
   "metadata": {},
   "source": [
    "- ray.init(): Initializes your Ray cluster. Pass in an address to connect to an existing cluster.\n",
    "- @ray.remote: Turns functions into tasks and classes into actors.\n",
    "- ray.put(): Puts values into Ray’s object store.\n",
    "- ray.get(): Gets valuyes from the object store. Returns the values you’ve put there or that were computed by a task or actor.\n",
    "- .remote(): Runs actor methods or tasks on your Ray cluster and is used to instantiate actors.\n",
    "- ray.wait(): Returns two lists of object references, one with finished tasks we’re waiting for and one with unfinished tasks.\n",
    "\n",
    "Now that you’ve seen the Ray API in action, let’s spend some time on its system\n",
    "architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ec7ae",
   "metadata": {},
   "source": [
    "## Ray System Components\n",
    "\n",
    "Now that you are familiar with using the Ray API and understand the design principles behind it, it is time to delve deeper into the inner workings of the Ray system. In other words, how does Ray operate and how does it accomplish its tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971af0c3",
   "metadata": {},
   "source": [
    "### Scheduling and Execution\n",
    "\n",
    "In the Ray cluster system, nodes are made up of individual units called workers. Each worker is identified by a unique ID, IP address, and port. These workers are responsible for carrying out tasks as instructed, but they have no control over when they are given tasks or what resources they have available to complete them. They also have no understanding of the context in which their tasks are being executed, as they do not coordinate with other workers. Before examining the larger cluster as a whole, it is important to understand the role of these individual worker nodes.\n",
    "\n",
    "To address these issues, each worker node has a component called _Raylet_. Think of\n",
    "Raylets as the smart components of a node, which manage the worker processes. Raylets are shared between jobs and consist of two components, namely a task\n",
    "scheduler and an object store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b9477",
   "metadata": {},
   "source": [
    "Let's first discuss object stores. In the example provided in this chapter, we have already used the concept of an object store without explicitly stating it. Each node in a Ray cluster is equipped with an object store within its Raylet and all objects stored in these stores form the distributed object store of the cluster. The object store manages the shared memory pool among workers on the same node and ensures that workers can access objects created on other nodes. The object store is implemented using Plasma, which is now part of the Apache Arrow project. Its main function is to manage memory and ensure that workers have access to the objects they need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf01ab2",
   "metadata": {},
   "source": [
    "The scheduler within a Raylet is responsible for managing resources, including assigning available worker processes to tasks that need access to certain resources such as CPUs. By default, the scheduler is aware of the number of CPUs, GPUs, and amount of memory available on its node. If the scheduler is unable to provide the necessary resources for a task, it must queue the task until resources become available. The scheduler also limits the number of tasks that can run concurrently to prevent overuse of physical resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0f791",
   "metadata": {},
   "source": [
    "The scheduler is responsible for ensuring that workers have all the necessary resources and dependencies in order to perform their tasks. To do this, the scheduler first checks its own object store for the required values. If these values are not present, the scheduler must reach out to other nodes to retrieve the necessary dependencies. Only once the scheduler has obtained the necessary resources, resolved all dependencies, and identified a worker for the task can it proceed with scheduling the task for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156144ca",
   "metadata": {},
   "source": [
    "Task scheduling can be challenging, even when only considering a single node. It is easy to envision situations where an improperly or poorly planned task execution can prevent downstream tasks from proceeding due to a lack of available resources. This issue can become even more complex in a distributed setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd3d2a",
   "metadata": {},
   "source": [
    "#### Fault Tolerance and Ownership\n",
    "\n",
    "Now that you have a understanding of Raylets, we will briefly revisit worker processes and conclude the discussion by briefly explaining how Ray is able to recover from failures and the necessary concepts for doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5da625",
   "metadata": {},
   "source": [
    "In summary, workers keep track of metadata for all tasks they initiate, as well as the object references returned by those tasks. This is known as ownership, which means that the process that generates an object reference is responsible for ensuring its proper execution and availability of results. Workers must maintain an ownership table to keep track of the tasks they are responsible for, in case any of them fail and need to be redone. This way, if a task fails, the worker already has all the necessary information to recompute it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcfb5c",
   "metadata": {},
   "source": [
    "To provide a clear illustration of an ownership relationship instead of the idea of dependency that was mentioned before, consider a program that initiates a basic task and then internally calls on another task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8783c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def task_owned():\n",
    "    return\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def task(dependency):\n",
    "    res_owned = task_owned.remote()\n",
    "    return\n",
    "\n",
    "\n",
    "val = ray.put(\"value\")\n",
    "res = task.remote(dependency=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29bfcf",
   "metadata": {},
   "source": [
    "To break down the ownership and dependencies in this example, we have two tasks - `task` and `task_owned` - and three variables - `val`, `res`, and `res_owned`. The main program owns `task`, `val`, and `res`, and also calls `task`. However, res depends on task, but there is no ownership relationship between the two. When `task` is called, it takes `val` as a dependency and then calls `task_owned`, which assigns `res_owned`, therefore owning both `task_owned` and `res_owned`. Lastly, `task_owned` does not own anything, but res_owned depends on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af38a967",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "![Worker Node](./images/chapter_02/worker_node.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811ae20",
   "metadata": {},
   "source": [
    "### The Head Node\n",
    "\n",
    "As previously mentioned in Chapter 1, each Ray cluster has a designated head node which has a driver process. While drivers are able to submit tasks, they are unable to execute them. It is also worth noting that the head node can also possess worker processes, which allows for the creation of single node local clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4a43c",
   "metadata": {},
   "source": [
    "The head node functions in the same way as other worker nodes, but it also runs processes that manage the cluster, such as the autoscaler and the Global Control Service (GCS). The GCS is a key-value store that contains important information about the cluster, including system-level metadata and the locations of Ray actors. It also receives and stores heart beat signals from Raylets to ensure they are still reachable, and sends its own heart beat signals to the Raylets to indicate that it is functioning properly. The ownership model ensures that object information is stored at the worker process responsible for it, preventing the GCS from becoming a bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd2093",
   "metadata": {},
   "source": [
    "### Distributed Scheduling and Execution\n",
    "\n",
    "We will discuss the process of cluster orchestration and how nodes manage, plan, and execute tasks. When discussing worker nodes, we previously mentioned that there are several components involved in distributing workloads using Ray. The following is a summary of the steps and details involved in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a1004",
   "metadata": {},
   "source": [
    "- _Distributed memory_: Each Raylet, which is a unit responsible for managing memory on a particular node, has its own object store. However, there are situations where objects need to be transferred between nodes, a process referred to as distributed object transfer. This occurs in order to address remote dependencies, ensuring that workers have access to the necessary objects to perform their tasks.\n",
    "- _Communication_: Most of the communication in a Ray cluster, such as object\n",
    "transfer, takes place via [gRPC](https://grpc.io/).\n",
    "- _Resource management and fulfillment_: The role of Raylets on a node is to assign resources and assign worker processes to task owners. The distributed scheduler, which consists of schedulers on all nodes, allows tasks to be scheduled on other nodes. Local schedulers are aware of the resources on other nodes through communication with the GCS.\n",
    "- _Task execution_: Before a task can be executed, all of its dependencies, including both local and remote data, must be resolved. For example, this might involve retrieving large data from the object store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78745f9",
   "metadata": {},
   "source": [
    "![Ray architecture](./images/chapter_02/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a4ee1",
   "metadata": {},
   "source": [
    "Now that you’ve learned the basics of the Ray Core API and know the fundamentals\n",
    "of Ray’s Cluster architecture, let’s compute one more complex example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dbcc2",
   "metadata": {},
   "source": [
    "## Running A MapReduce Example\n",
    "\n",
    "It would be remiss to conclude this conversation without mentioning MapReduce, a significant development in distributed computing in recent decades. Many popular big data technologies, such as Hadoop, are built upon this programming model, and it is worth discussing in relation to Ray. To illustrate its use, we will use a simple example of counting word occurrences across multiple documents. While this may seem like a straightforward task when working with a small number of documents, it becomes more complex when dealing with a large corpus, requiring the use of multiple compute nodes to process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59dc10",
   "metadata": {},
   "source": [
    "A MapReduce word-count example is a commonly used example in distributed computing and is worth learning about. The approach involves three simple steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae37e0a",
   "metadata": {},
   "source": [
    "1. Use a set of documents as the input and apply a specified function to transform or \"map\" each element within them (such as the words contained in the documents). This map phase will produce key-value pairs, where the key represents an element in the document and the value is a metric calculated for that element. In this particular case, the goal is to count the number of times each word appears in a document, so the map function will output the pair `(word, 1)` every time a word is encountered to show that it has been found once.\n",
    "2. All of the outputs from the map phase are collected and organized based on their key. This may involve transferring data between different nodes, as the same key could potentially be found on multiple compute nodes. This process is commonly referred to as the shuffle phase. As an example, if the map phase produces four occurrences of the pair `(word, 1)`, the shuffle phase will ensure that all occurrences of the same word are located on the same node.\n",
    "3. The reduce phase is so named because it aggregates or combines the elements from the shuffle step. Using the example provided, the final count of a word's occurrences is obtained by adding up all of the occurrences on each node. For example, four instances of `(word, 1)` would be combined to result in a final count of `word: 4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd5e5e",
   "metadata": {},
   "source": [
    "MapReduce is named after the first and last stages of the process, but the middle stage is just as crucial. These phases may appear straightforward, but their strength lies in the ability to run them concurrently on multiple machines. An example of using the three MapReduce phases on a set of documents divided into three parts is shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b1af6",
   "metadata": {},
   "source": [
    "\n",
    "![Simple Map Reduce](./images/chapter_02/map_reduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225ae60",
   "metadata": {},
   "source": [
    "We will be using Python to implement the MapReduce algorithm for our word-count purpose and utilizing Ray to parallelize the computation. To better understand what we are working with, we will begin by loading some example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c6ddc0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "zen_of_python = subprocess.check_output([\"python\", \"-c\", \"import this\"])\n",
    "corpus = zen_of_python.split()\n",
    "\n",
    "num_partitions = 3\n",
    "chunk = len(corpus) // num_partitions\n",
    "partitions = [\n",
    "    corpus[i * chunk: (i + 1) * chunk] for i in range(num_partitions)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96c181",
   "metadata": {},
   "source": [
    "We will be using the Zen of Python, a collection of guidelines from the Python community, as our data for this exercise. The Zen of Python can be accessed by typing \"import this\" in a Python session and is traditionally hidden as an \"Easter egg.\" While it is beneficial for Python programmers to read these guidelines, for the purposes of this exercise, we will only be counting the number of words contained within them. To do this, we will divide the Zen of Python into three separate \"documents\" by treating each line as a separate entity and then splitting it into these partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357e924",
   "metadata": {},
   "source": [
    "To determine the map phase, we require a map function that we will utilize on each document. In this particular scenario, we want to output the pair `(word, 1)` for every word found in a document. For basic text documents that are loaded as Python strings, this process appears as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742193e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(document):\n",
    "    for word in document.lower().split():\n",
    "        yield word, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52009879",
   "metadata": {},
   "source": [
    "We will use the apply_map function on a large collection of documents by marking it as a task in Ray using the `@ray.remote` decorator. When we call `apply_map`, it will be applied to three sets of document data (`num_partitions=3`). The `apply_map` function will return three lists, one for each partition. We do this so that Ray can rearrange the results of the map phase and distribute them to the appropriate nodes for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2fed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "@ray.remote\n",
    "def apply_map(corpus, num_partitions=3):\n",
    "    map_results = [list() for _ in range(num_partitions)]\n",
    "    for document in corpus:\n",
    "        for result in map_function(document):\n",
    "            first_letter = result[0].decode(\"utf-8\")[0]\n",
    "            word_index = ord(first_letter) % num_partitions\n",
    "            map_results[word_index].append(result)\n",
    "    return map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba13f8",
   "metadata": {},
   "source": [
    "For text corpora that can be stored on a single machine, it is unnecessary to use the map phase. However, when the data needs to be divided across multiple nodes, the map phase becomes useful. In order to apply the map phase to our corpus in parallel, we use a remote call on apply_map, just like we have done in previous examples. The main difference now is that we also specify that we want three results returned (one for each partition) using the num_returns argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "360b19b8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapper 0, return value 0: [(b'of', 1), (b'is', 1)]\n",
      "Mapper 0, return value 1: [(b'python,', 1), (b'peters', 1)]\n",
      "Mapper 0, return value 2: [(b'the', 1), (b'zen', 1)]\n",
      "Mapper 1, return value 0: [(b'unless', 1), (b'in', 1)]\n",
      "Mapper 1, return value 1: [(b'although', 1), (b'practicality', 1)]\n",
      "Mapper 1, return value 2: [(b'beats', 1), (b'errors', 1)]\n",
      "Mapper 2, return value 0: [(b'is', 1), (b'is', 1)]\n",
      "Mapper 2, return value 1: [(b'although', 1), (b'a', 1)]\n",
      "Mapper 2, return value 2: [(b'better', 1), (b'than', 1)]\n"
     ]
    }
   ],
   "source": [
    "map_results = [\n",
    "    apply_map.options(num_returns=num_partitions)\n",
    "    .remote(data, num_partitions)\n",
    "    for data in partitions\n",
    "]\n",
    "\n",
    "for i in range(num_partitions):\n",
    "    mapper_results = ray.get(map_results[i])\n",
    "    for j, result in enumerate(mapper_results):\n",
    "        print(f\"Mapper {i}, return value {j}: {result[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171744b1",
   "metadata": {},
   "source": [
    "We can make it so that all pairs from the `j`-th return value end up on\n",
    "the same node for the reduce phase. Let’s discuss this phase next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6774619",
   "metadata": {},
   "source": [
    "In the reduce phase we can create a dictionary that sums up all word\n",
    "occurrences on each partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5891b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def apply_reduce(*results):\n",
    "    reduce_results = dict()\n",
    "    for res in results:\n",
    "        for key, value in res:\n",
    "            if key not in reduce_results:\n",
    "                reduce_results[key] = 0\n",
    "            reduce_results[key] += value\n",
    "\n",
    "    return reduce_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee3c55",
   "metadata": {},
   "source": [
    "We can take the j-th return value from each mapper and send it to the j-th reducer using the following method. It's important to note that this code works for larger datasets that don't fit on one machine because we are passing references to the data using Ray objects rather than the actual data itself. Both the map and reduce phases can be run on any Ray cluster and the data shuffling is also handled by Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a395a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is: 10\n",
      "better: 8\n",
      "than: 8\n",
      "the: 6\n",
      "to: 5\n",
      "of: 3\n",
      "although: 3\n",
      "be: 3\n",
      "unless: 2\n",
      "one: 2\n",
      "if: 2\n",
      "implementation: 2\n",
      "idea.: 2\n",
      "special: 2\n",
      "should: 2\n",
      "do: 2\n",
      "may: 2\n",
      "a: 2\n",
      "never: 2\n",
      "way: 2\n",
      "explain,: 2\n",
      "ugly.: 1\n",
      "implicit.: 1\n",
      "complex.: 1\n",
      "complex: 1\n",
      "complicated.: 1\n",
      "flat: 1\n",
      "readability: 1\n",
      "counts.: 1\n",
      "cases: 1\n",
      "rules.: 1\n",
      "in: 1\n",
      "face: 1\n",
      "refuse: 1\n",
      "one--: 1\n",
      "only: 1\n",
      "--obvious: 1\n",
      "it.: 1\n",
      "obvious: 1\n",
      "first: 1\n",
      "often: 1\n",
      "*right*: 1\n",
      "it's: 1\n",
      "it: 1\n",
      "idea: 1\n",
      "--: 1\n",
      "let's: 1\n",
      "python,: 1\n",
      "peters: 1\n",
      "simple: 1\n",
      "sparse: 1\n",
      "dense.: 1\n",
      "aren't: 1\n",
      "practicality: 1\n",
      "purity.: 1\n",
      "pass: 1\n",
      "silently.: 1\n",
      "silenced.: 1\n",
      "ambiguity,: 1\n",
      "guess.: 1\n",
      "and: 1\n",
      "preferably: 1\n",
      "at: 1\n",
      "you're: 1\n",
      "dutch.: 1\n",
      "good: 1\n",
      "are: 1\n",
      "great: 1\n",
      "more: 1\n",
      "zen: 1\n",
      "by: 1\n",
      "tim: 1\n",
      "beautiful: 1\n",
      "explicit: 1\n",
      "nested.: 1\n",
      "enough: 1\n",
      "break: 1\n",
      "beats: 1\n",
      "errors: 1\n",
      "explicitly: 1\n",
      "temptation: 1\n",
      "there: 1\n",
      "that: 1\n",
      "not: 1\n",
      "now: 1\n",
      "never.: 1\n",
      "now.: 1\n",
      "hard: 1\n",
      "bad: 1\n",
      "easy: 1\n",
      "namespaces: 1\n",
      "honking: 1\n",
      "those!: 1\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(num_partitions):\n",
    "    outputs.append(\n",
    "        apply_reduce.remote(*[partition[i] for partition in map_results])\n",
    "    )\n",
    "\n",
    "counts = {k: v for output in ray.get(outputs) for k, v in output.items()}\n",
    "\n",
    "sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "for count in sorted_counts:\n",
    "    print(f\"{count[0].decode('utf-8')}: {count[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bd93b",
   "metadata": {},
   "source": [
    "To gain a thorough understanding of how to scale MapReduce tasks across multiple nodes using Ray, including memory management, we suggest reading this [insightful blog post on the topic](https://medium.com/distributed-computing-with-ray/executing-adistributed-shuffle-without-a-mapreduce-system-d5856379426c).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fb217-f8f0-4404-9150-aeddea120e51",
   "metadata": {},
   "source": [
    "The important part about this MapReduce example is to realize how flexible Ray’s\n",
    "programming model really is. Surely, a production-grade MapReduce implementation\n",
    "takes a bit more effort. But being able to reproduce common algorithms like this\n",
    "one quickly goes a long way. Keep in mind that in the earlier phases of MapReduce,\n",
    "say around 2010, this paradigm was often the only thing you had to express your\n",
    "workloads. With Ray, a whole range of interesting distributed computing patterns\n",
    "become accessible to any intermediate Python programmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f957170-c8ad-48f1-8d95-8bdee472633c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
